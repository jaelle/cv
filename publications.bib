
@article{golob_auditory_2021,
	title = {Auditory spatial attention gradients and cognitive control as a function of vigilance},
	volume = {58},
	copyright = {© 2021 Society for Psychophysiological Research},
	issn = {1469-8986},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/psyp.13903},
	doi = {10.1111/psyp.13903},
	abstract = {Selection and effort are central to attention, yet it is unclear whether they draw on a common pool of cognitive resources, and if so, whether there are differences for early versus later stages of cognitive processing. This study assessed effort by quantifying the vigilance decrement, and spatial processing at early and later stages as a function of time-on-task. Participants performed an auditory spatial attention task, with occasional “catch” trials requiring no response. Psychophysiological measures included bilateral cerebral blood flow (transcranial Doppler), pupil dilation, and blink rate. The shape of attention gradients using reaction time indexed early processing, and did not significantly vary over time. Later stimulus-response conflict was comparable over time, except for a reduction to left hemispace stimuli. Target and catch trial accuracy decreased with time, with a more abrupt decrease for catch versus target trials. Diffusion decision modeling found progressive decreases in information accumulation rate and non-decision time, and the adoption of more liberal response criteria. Cerebral blood flow increased from baseline and then decreased over time, particularly in the left hemisphere. Blink rate steadily increased over time, while pupil dilation increased only at the beginning and then returned towards baseline. The findings suggest dissociations between resources for selectivity and effort. Measures of high subjective effort and temporal declines in catch trial accuracy and cerebral blood flow velocity suggest a standard vigilance decrement was evident in parallel with preserved selection. Different attentional systems and classes of computations that may account for dissociations between selectivity versus effort are discussed.},
	language = {en},
	number = {10},
	urldate = {2025-09-28},
	journal = {Psychophysiology},
	author = {Golob, Edward J. and Nelson, Jeremy T. and Scheuerman, Jaelle and Venable, Kristen B. and Mock, Jeffrey R.},
	year = {2021},
	pages = {e13903},
}

@misc{michael_interactive_2020,
	title = {On Interactive Machine Learning and the Potential of Cognitive Feedback},
	url = {http://arxiv.org/abs/2003.10365},
	doi = {10.48550/arXiv.2003.10365},
	abstract = {In order to increase productivity, capability, and data exploitation, numerous defense applications are experiencing an integration of state-of-the-art machine learning and AI into their architectures. Especially for defense applications, having a human analyst in the loop is of high interest due to quality control, accountability, and complex subject matter expertise not readily automated or replicated by AI. However, many applications are suffering from a very slow transition. This may be in large part due to lack of trust, usability, and productivity, especially when adapting to unforeseen classes and changes in mission context. Interactive machine learning is a newly emerging field in which machine learning implementations are trained, optimized, evaluated, and exploited through an intuitive human-computer interface. In this paper, we introduce interactive machine learning and explain its advantages and limitations within the context of defense applications. Furthermore, we address several of the shortcomings of interactive machine learning by discussing how cognitive feedback may inform features, data, and results in the state of the art. We define the three techniques by which cognitive feedback may be employed: self reporting, implicit cognitive feedback, and modeled cognitive feedback. The advantages and disadvantages of each technique are discussed.},
	urldate = {2025-09-28},
	publisher = {arXiv},
	author = {Michael, Chris J. and Acklin, Dina and Scheuerman, Jaelle},
	month = mar,
	year = {2020},
}

@incollection{scheuerman_designing_2021,
	title = {Designing Interactive Machine Learning Systems for GIS Applications},
	isbn = {978-3-030-89385-9},
	url = {https://doi.org/10.1007/978-3-030-89385-9_9},
	abstract = {Geospatial information systems (GIS) support decision making and situational awareness in a wide variety of applications. These systems often require large amounts of labeled data to be displayed in a way that is easy to use and understand. Manually editing these information displays can be extremely time-consuming for an analyst. Algorithms have been designed to alleviate some of this work by automatically generating map displays or digitizing features. However, these systems regularly make mistakes, requiring analysts to verify and correct their output. This human-in-the-loop process of validating the algorithm’s labels can provide a means to continuously improve a model over time by using interactive machine learning (IML). This process allows for systems that can function with little or no training data and as the features continue to evolve. Such systems must also account for the strengths and limitations of both the analysts and underlying algorithms to avoid unnecessary frustration, encourage adoption, and increase productivity of the human-machine team. In this chapter, we introduce three examples of how IML has been used in GIS systems for airfield change detection, geographic region digitization and digital map editing. We also describe several considerations for designing IML workflows to ensure that the analyst and system complement one another, resulting in increased productivity and quality of the GIS output. Finally, we will consider new challenges that arise when applying IML to the complex task of automatic map labeling.},
	language = {en},
	urldate = {2025-09-28},
	booktitle = {Engineering {Artificially} {Intelligent} {Systems}: {A} {Systems} {Engineering} {Approach} to {Realizing} {Synergistic} {Capabilities}},
	publisher = {Springer International Publishing},
	author = {Scheuerman, Jaelle and Michael, Chris J. and Landreneau, Brad and Acklin, Dina M. and Harman, Jason L.},
	editor = {Lawless, William F. and Llinas, James and Sofge, Donald A. and Mittu, Ranjeev},
	year = {2021},
	doi = {10.1007/978-3-030-89385-9_9},
	pages = {147--158},
}

@article{harman_simple_2023,
	title = {Simple rules outperform machine learning for personnel selection: insights from the 3rd annual {SIOP} machine learning competition},
	volume = {3},
	issn = {2731-0809},
	shorttitle = {Simple rules outperform machine learning for personnel selection},
	url = {https://doi.org/10.1007/s44163-022-00044-2},
	doi = {10.1007/s44163-022-00044-2},
	abstract = {Machine learning (ML) algorithms are often assumed to be the most accurate way of producing predictive models despite problems with explainability and adverse impact. The 3rd annual Society for Industrial and Organizational Psychology Machine Learning Competition sought to find ML models for personnel selection that could balance the best of ML prediction with the constraint of minimizing selection bias based on race and gender. To test the possible advantages of simple rules over ML algorithms, we entered a simple and explainable rule-based model inspired by recent advances in model comparison. This simple model outperformed most ML models entered and was comparable to the top performers while retaining positive qualities such as explainability and transparency.},
	language = {en},
	number = {1},
	urldate = {2025-09-28},
	journal = {Discover Artificial Intelligence},
	author = {Harman, Jason L. and Scheuerman, Jaelle},
	month = jan,
	year = {2023},
	pages = {2},
}

@article{bishof_closed-loop_2023,
	title = {Closed-Loop Uncertainty: The Evaluation and Calibration of Uncertainty for Human–Machine Teams under Data Drift},
	volume = {25},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	shorttitle = {Closed-{Loop} {Uncertainty}},
	url = {https://www.mdpi.com/1099-4300/25/10/1443},
	doi = {10.3390/e25101443},
	abstract = {Though an accurate measurement of entropy, or more generally uncertainty, is critical to the success of human–machine teams, the evaluation of the accuracy of such metrics as a probability of machine correctness is often aggregated and not assessed as an iterative control process. The entropy of the decisions made by human–machine teams may not be accurately measured under cold start or at times of data drift unless disagreements between the human and machine are immediately fed back to the classifier iteratively. In this study, we present a stochastic framework by which an uncertainty model may be evaluated iteratively as a probability of machine correctness. We target a novel problem, referred to as the threshold selection problem, which involves a user subjectively selecting the point at which a signal transitions to a low state. This problem is designed to be simple and replicable for human–machine experimentation while exhibiting properties of more complex applications. Finally, we explore the potential of incorporating feedback of machine correctness into a baseline naïve Bayes uncertainty model with a novel reinforcement learning approach. The approach refines a baseline uncertainty model by incorporating machine correctness at every iteration. Experiments are conducted over a large number of realizations to properly evaluate uncertainty at each iteration of the human–machine team. Results show that our novel approach, called closed-loop uncertainty, outperforms the baseline in every case, yielding about 45\% improvement on average.},
	language = {en},
	number = {10},
	urldate = {2025-09-28},
	journal = {Entropy},
	author = {Bishof, Zachary and Scheuerman, Jaelle and Michael, Chris J.},
	month = oct,
	year = {2023},
	pages = {1443},
}

@misc{harman_multi-criteria_2024,
	title = {Multi-Criteria Comparison as a Method of Advancing Knowledge-Guided Machine Learning},
	url = {http://arxiv.org/abs/2403.11840},
	doi = {10.48550/arXiv.2403.11840},
	abstract = {This paper describes a generalizable model evaluation method that can be adapted to evaluate AI/ML models across multiple criteria including core scientific principles and more practical outcomes. Emerging from prediction competitions in Psychology and Decision Science, the method evaluates a group of candidate models of varying type and structure across multiple scientific, theoretic, and practical criteria. Ordinal ranking of criteria scores are evaluated using voting rules from the field of computational social choice and allow the comparison of divergent measures and types of models in a holistic evaluation. Additional advantages and applications are discussed.},
	urldate = {2025-09-28},
	publisher = {arXiv},
	author = {Harman, Jason L. and Scheuerman, Jaelle},
	month = mar,
	year = {2024},
}

@article{scheuerman_framework_2024,
	title = {A Framework for Enhancing Behavioral Science Research with Human-Guided Language Models},
	volume = {3},
	copyright = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
	issn = {2994-4317},
	url = {https://ojs.aaai.org/index.php/AAAI-SS/article/view/31206},
	doi = {10.1609/aaaiss.v3i1.31206},
	abstract = {Many behavioral science studies result in large amounts of unstructured data sets that are costly to code and analyze, requiring multiple reviewers to agree on systematically chosen concepts and themes to categorize responses. Large language models (LLMs) have potential to support this work, demonstrating capabilities for categorizing, summarizing, and otherwise organizing unstructured data. In this paper, we consider that although LLMs have the potential to save time and resources performing coding on qualitative data, the implications for behavioral science research are not yet well understood. Model bias and inaccuracies, reliability, and lack of domain knowledge all necessitate continued human guidance. New methods and interfaces must be developed to enable behavioral science researchers to efficiently and systematically categorize unstructured data together with LLMs. We propose a framework for incorporating human feedback into an annotation workflow, leveraging interactive machine learning to provide oversight while improving a language model's predictions over time.},
	language = {en},
	number = {1},
	urldate = {2025-09-28},
	journal = {Proceedings of the AAAI Symposium Series},
	author = {Scheuerman, Jaelle and Acklin, Dina},
	month = may,
	year = {2024},
	pages = {243--247},
}

@inproceedings{scheuerman_beyond_2025,
	title = {Beyond Explicit Instruction Enhancing Human-AI Collaboration with Implicit User Feedback},
	volume = {163},
	isbn = {978-1-964867-39-7},
	shorttitle = {Beyond {Explicit} {Instruction}},
	url = {https://openaccess.cms-conferences.org/publications/book/978-1-964867-39-7/article/978-1-964867-39-7_19},
	doi = {10.54941/ahfe1006049},
	abstract = {Successful human-AI teamwork depends on AI systems that can adjust to the evolving needs and situations of users. Rather than relying on explicit instructions from the user, an adaptable agent can make use of implicit feedback from end-users to infer user's behavioral and situational needs. Implicit information, such as user activity and eye tracking data, can help infer behavioral patterns that uncover the user's desires, requirements, and mental states. This method allows AI systems to deliver more tailored, proactive and wholistic assistance, which not only minimizes user’s real-time workload, but also serves to add redundancy to human-error, much like a beneficial human teammate. While this approach offers several potential advantages, there are practical difficulties in gathering and interpreting the data. Upcoming efforts to deduce high-level actions from low-level data will need to tackle these challenges to facilitate intuitive human-AI interactions and improve theefficacy of collaborative systems.},
	language = {eng},
	urldate = {2025-09-28},
	booktitle = {Artificial {Intelligence} and {Social} {Computing}},
	publisher = {AHFE Open Acces},
	author = {Scheuerman, Jaelle and Mcgarry, Shannon and Sibley, Ciara and Brown, Noelle},
	year = {2025},
}

@article{scheuerman_adapting_2025,
	title = {Adapting Language Model Responses with Implicit Feedback for Effective Human-AI Collaboration},
	volume = {5},
	copyright = {Copyright (c) 2025 Association for the Advancement of Artificial Intelligence},
	issn = {2994-4317},
	url = {https://ojs.aaai.org/index.php/AAAI-SS/article/view/35568},
	doi = {10.1609/aaaiss.v5i1.35568},
	abstract = {To be effective teammates with humans, is necessary for AI systems to deduce user state and context from implicitly collected feedback. In this extended abstract, we explore ways in which user activity and eyetracking systems can provide implicit feedback for the purpose of adapting the AI model to user's changing goals and needs.},
	language = {en},
	number = {1},
	urldate = {2025-09-28},
	journal = {Proceedings of the AAAI Symposium Series},
	author = {Scheuerman, Jaelle and McGarry, Shannon and Sibley, Ciara and Brown, Noelle},
	month = may,
	year = {2025},
	pages = {98--99},

